---
title: "shadowVIMP-vignette_v2"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{shadowVIMP-vignette_v2}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction to `shadowVIMP` package

## Theoretical framework

### Motivation

When working with high-dimensional data, it is often desirable to reduce the number of covariates considered. This reduction can help prevent overfitting, as too many covariates can cause the model to capture noise instead of the true relationship between predictors and outcome. In addition, using fewer covariates improves the interpretability of the model, making it easier to understand, and improves computational efficiency. In some cases, where the primary objective is to understand which variables contribute most to the accuracy of the model, reducing the number of covariates is key. There are several established methods of variable selection. The `shadowVIMP` package introduces a new variable selection method based on variable importance (VIMP) from the random forest (RF) algorithm. In short, the VIMP of a covariate *j* measures the increase in prediction error when that variable is randomly permuted. If a predictor *j* has a large impact on the outcome of interest, it will produce a relatively large VIMP compared to uninformative covariates.VIMPs only allow us to rank covariates by their relative importance, but the absolute magnitude of a VIMP is context dependent, i.e. there is no universal cut-off for identifying truly important variables. Therefore, a simple approach of selecting covariates with a VIMP above a certain threshold is not appropriate as it could lead to arbitrary choices. Another common method is to select the top *n* predictors (e.g. top 5, 10 or 20), but this approach risks missing important variables or selecting false positives, especially if few or none of the covariates are related to the outcome. Therefore, a more reliable approach is needed to ensure that observed VIMPs are not simply due to chance. This is where the `shadowVIMP` package comes in. `shadowVIMP` provides a statistical framework for assessing whether a given VIMP is large enough to be considered statistically significant. In other words, it helps answer the question whether a given VIMP is large enough that it is unlikely to occur by chance.

### Big picture

As mentioned in the previous chapter, we aim to conduct a statistical test to determine whether a VIMP associated with a given covariate is statistically significant. However, there is a challenge: we do not have a null distribution for the VIMPs. The `shadowVIMP` package provides the following solution to this problem:

1. **Approximate null distribution**: Similar to the permutation testing approach, approximate the null distribution by generating values through permutations.
2. **Calculate p-values**: Determine the proportion of iterations in which the VIMP of the randomly permuted variable exceeds the median VIMP of the original variable. 
3. **Compare p-values**: Compare the calculated p-values to the pre-specified significance level to make the final decision.

### Gready details

The procedure implemented in the `shadowVIMP` package can be described as follows:

1. For each of the *p* covariates in the dataset, create *p* r-shadow variables by permuting rows of copied original covariates, thereby removing any association with the outcome (see the figure below). These uninformative r-shadow variables serve as a reference for evaluating the importance of the original predictors. Repeat this permutation process *nsim* times, generating new r-shadow variables in each iteration.

```{r, echo=FALSE, out.width="85%", fig.cap="Permutation scheme"}
knitr::include_graphics("rshadow.png")
```

2.  For each of the `nsim` permutations, run the random forest model and calculate VIMP of the original and r-shadow covariates. After *nsim* iterations, the algorithm produces a data frame with *nsim* rows and *2p* columns containing VIMPs for both original and r-shadow variables. This process establishes a null distribution of VIMPs. Between iterations, the r-shadow VIMPs vary due to permutation, and the VIMPs of the original covariates vary due to the inherent randomness of the random forest. 

3. Calculate and decide whether a covariate *j* is significant based on its non-parametric p-value. The p-value for variable *j* is defined as follows:

$$p_{j} = 1 - \widehat{F}_{ \left\{VI_{j}^{(s)}, \infty \right\}}(median(VI_{j}))$$

where:

* $\widehat{F}_{\{VI_{j}^{(s)}, \infty\}}(\cdot)$ is an empirical cumulative distribution function (ECDF) based on the r-shadow VIMPs of variable *j* with an infinity added. Adding infinity to the ECDF introduces a small offset to prevent p-values being exactly 0.
* $median(VI_{j})$ is the median of the VIMPs of the original variables over all `nsin` iterations of the random forest.

In the rest of this tutorial, we will call this type of p-value **per-variable p-value**. Such a defined p-value represents a proportion of iterations in which the r-shadow variable achieved a higher VIMP than the median VIMP of the original variable. The covariate $x_{j}$ is considered informative if, for a given significance level $\alpha$, the following inequality holds:

$$p_{j} \le \alpha$$

#### High-dimensional data extension 1: pre-selection 

The method described above is works well for low-dimensional data, but high-dimensional settings require modifications.  The first improvement we need for a high-dimensional setting is the **pre-selection** of covariates to eliminate uninformative variables early on. This involves reducing the set of predictors in one or more preliminary steps using a less strict significance level ($\alpha$) than the final target (e.g., $\alpha = 0.3$ for pre-selection when the final $\alpha = 0.05$). The figure below illustrates the pre-selection procedure implemented in the `shadowVIMP` package.

```{r, echo=FALSE, out.width="85%", fig.cap="Illustration of pre-selection procedure"}
knitr::include_graphics("preselection.png")
```

**Pre-selection process**:

1. **Initial pre-selection**: Run the algorithm with $\alpha = 0.3$ (possibly with fewer iterations, here $30$) to identify variables with p-values $ \leq 0.3$.
2. **Second step of pre-selection** (optional): Further reduce the set of variables by applying a stricter threshold (e.g., $\alpha = 0.1$) using more RF iterations (here $120$).
3. **Final selection**: Only variables that pass all the pre-selection steps proceed to the final step of the algorithm, ensuring that they have the potential to meet the target significance level of $0.05$.
 
#### Addressing multiple testing issue

The defined decision criterion, namely the per-variable p-value, directly compares the VIMPs of the original variable with with the VIMPs of its corresponding r-shadow variable. In practice, especially when analysing high-dimensional data, multiple testing should be addressed by appropriate p-value adjustment method. The `shadowVIMP` package provides two adjustment procedures:  Benjamini-Hochberg (BH), which controls for the expected false discovery rate (FDR), and the Holm procedure, which controls for the family-wise error rate (FWER) 

#### High-dimensional data extension 2: pooled p-value

When performing numerous statistical tests, the application of multiple testing adjustment method is necessary. This requires calculating very small p-values. For example, with $5,000$ predictors in the data set and a target significance level of $0.05$, when using the Benjamini-Hochberg (BH) adjustment, the first significance threshold is $0.05/5000 = 0.00001$. This means that to reject the null hypothesis (a covariate is uninformative) for the variable with the smallest p-value, its p-value must be $\leq 0.00001$. Given the present definition of p-value, the smallest achievable p-value is $\frac{1}{n_{sim}}$. Therefore, to achieve a p-value lower than the significance threshold, we would need $\frac{5000}{0.05} = 100000$ iterations of the random forest. Performing such a large number of iterations would be computationally expensive. 

To reduce computational cost, we introduce the **pooled p-value** as an alternative decision criterion. Pooling increases the effective sample size of the ECDF by incorporating VIMP values of all r-shadow variables instead of just one. Before pooling,  it is essential to standardise the r-shadow VIMPs to ensure comparable distributions. The pooled p-value for covariate *j* is then defined as follows:

$$
p_j^{(\text{pooled})} = 1 - \widehat{F}_{ \left\{ \widetilde{VI}_{1}^{(s)}, \dots, \widetilde{VI}_{j}^{(s)}, \dots, \widetilde{VI}_{p}^{(s)}, \infty \right\} } \left( \text{median} \left( \widetilde{VI}_{j} \right) \right)
$$


where $\widetilde{VI}_{j}^{(s)}$ is a set of standardised r-shadow VIMPs and $\widetilde{VI}_{j}$ is the standardised VIMP of the original covariate $x_{j}$. Similar to per-variable p-values, when using the alternative decision criterion, the covariate j is considered informative if:

$$ p_j^{(\text{pooled})} \leq \alpha $$
The main advantage of pooled p-values is the reduced run time. Using the same example with $5000$ predictors as before, the smallest achievable p-value is $\frac{1}{n_{sim} \times 5000}$. The pooled decision criterion decreases the number of required iterations by a factor of 5,000 (or, more generally, by the number of covariates included in the data), making it possible (though not guaranteed) to reject at least one hypothesis. For analyses involving multiple testing adjustment, the authors of the paper behind this package strongly **recommend adopting the pooled decision criterion**.

#### Back to pre-selection

The current implementation of the `shadowVIMP` package uses pooled p-values in the preselection steps. In the final step of the procedure, the user can decide whether to report per-variable or pooled p-values along with the decisions based on them. More on this topic in the following practical guide to the `shadowVIMP` package.

## Quick start

The purpose of this section is to give users a general idea of the package. First, let's install the `shadowVIMP` package, which is not (yet!) available on Cran, but you can install the development version like this:

``` {r, eval = FALSE}
# Modify the code below with your credentials
devtools::install_git("https://gitlab.staburo.de/oktawia.miluch/shadowVIMP-package.git",
  credentials = git2r::cred_user_pass("YOUR-GITLAB-USERNAME", "YOUR-PAT-TOKEN")
)
```

Then, we load necessary packages:
```{r setup, warning = FALSE, message = FALSE}
library(shadowVIMP)
library(magrittr)
library(dplyr)

if (requireNamespace("AppliedPredictiveModeling", quietly = TRUE)) {
  library(AppliedPredictiveModeling)
} else {
  stop("Package 'AppliedPredictiveModeling' is required for this vignette. Please install it.")
}
```

In the examples below we use Alzheimer’s Disease CSF data from the `AppliedPredictiveModeling` package. To reduce the time needed to build this vignette, we use the subset of 100 observations from the original data and lower `nsims` values than recommended. For real-world analyses, please use the default or higher than below values of `nsims` parameter. In the example below, we show the basic usage of our package. By default, the functions of this package display informative covariates based on pooled p-values and display all p-value types: unadjusted, FWER-adjusted, and FDR-adjusted.

```{r ex_default}
data(AlzheimerDisease)
data_alz <- cbind(diagnosis, predictors)
# To make the results reproducible
set.seed(786)
data_sub <- slice_sample(data_alz, n = 100)
vimp_def <- vim_perm_sim_wrapper(nsims = c(20, 30, 50), entire_data = data_sub, outcome_var = "diagnosis")
```

As shown below, in this case none of the variables are informative when applying the Holm p-value correction (column `FWER_confirmed`). Using the FDR p-value correction, the first 5 covariates appear to be informative.  

````{r ex_default2}
vimp_def$final_dec_pooled %>%
  select(-quantile_pooled) %>%
  head()
````

## Select output components

The `vim_perm_sim_wrapper()` function has a `save_vimp_history` argument, allowing users to specify what is stored in the output object. By default, it is set to `"all"`, which saves variable importance measures from every step of the procedure. To inspect the VIMPs from the first or second simulation steps in the previously created object, use the following command:

````{r inspect_history1}
# VIMP history from the 1st step for 5 covariates
vimp_def$pre_selection$step_1$vimp_history %>%
  select(1:5) %>%
  head()

# VIMP history from the 2nd step
vimp_def$pre_selection$step_2$vimp_history %>%
  select(1:5) %>%
  head()
````

To check the VIMP measures from the last step run:

````{r vimp_last_step}
vimp_def$vimp_history %>%
  select(1:5) %>%
  head()
````

Setting the  `save_vimp_history` to `"last"` saves only the variable importance from the final step of the procedure. Unlike the default setting, this option does not save the VIMPs obtained in the pre-selection phase.

````{r vimp_last}
vimp_last <- vim_perm_sim_wrapper(nsims = c(20, 30, 50), entire_data = data_sub, outcome_var = "diagnosis", save_vimp_history = "last")

# Inspect VIMP from the last step of the procedure
vimp_last$vimp_history %>%
  select(1:6) %>%
  head()

# There is no `vimp_history`data frame under `pre_selection$step_1` or `pre_selection$step_2`
# vimp_last$pre_selection$step_1
# vimp_last$pre_selection$step_2
````

When `save_vimp_history` is set to `"none"`, variable importance won’t be saved for any steps. As shown below, under `vimp_history` there is no longer a data frame storing variable importance measures. Similarly, accessing `vimp_none$pre_selection$step_1` or `vimp_none$pre_selection$step_2` will not display data frames storing VIMPs from the pre-selection phase.

````{r vimp_none}
vimp_none <- vim_perm_sim_wrapper(nsims = c(20, 30, 50), entire_data = data_sub, outcome_var = "diagnosis", save_vimp_history = "none")
vimp_none$vimp_history
````

## Parallelisation

To speed up the computation, it is possible to run the main function of the `shadowVIMP` package in parallel. There are two ways to do this. The first is to use the parallelisation provided by the `ranger::ranger()` function used internally by the package. To use this functionality, the `num.threads` parameter must be set to a value greater than 1.

````{r parallel1}
vimp_parallel1 <- vim_perm_sim_wrapper(nsims = c(20, 30, 50), entire_data = data_sub, outcome_var = "diagnosis", num.threads = 4)
````

Another way to perform parallel computation is to set the `num_cores_parallel` parameter to a value greater than 1. In this case, a cluster with the specified number of cores is created under the hood.

````{r parallel2, results='hide'}
# Technical checks
# Detect if running on non-interactive environments
is_interactive <- interactive()

if (is_interactive) {
  # When interactive - run parallel
  num_cores <- min(parallel::detectCores(), 4)
  vimp_parallel2 <- vim_perm_sim_wrapper(
    nsims = c(20, 30, 50), entire_data = data_sub, outcome_var = "diagnosis",
    num_cores_parallel = num_cores
  )
} else {
  # When non-interactive - run sequantial
  vimp_parallel2 <- vim_perm_sim_wrapper(nsims = c(20, 30, 50), entire_data = data_sub, outcome_var = "diagnosis")
}
````

While it is possible to use two types of parallelization simultaneously, the package authors do not recommend doing so. In any case, it is important to set these parameters so they do not exceed the number of available cores on your machine. If you are unsure about the number of cores, run `parallel::detectCores()`. Note that for small datasets or low values of the `nsims` parameter, the benefit of parallelisation (if any) may be negligible.

## Choose decision criteria for the final decision

By default, the decision on whether a covariate is informative is based on the pooled p-value. However, per-variable p-values can also be used to select informative covariates in the final step of the procedure. In the output below, the informativeness of covariates is determined based on per-variable p-values:

````{r per_variable}
vimp_per_variable <- vim_perm_sim_wrapper(nsims = c(20, 30, 50), entire_data = data_sub, outcome_var = "diagnosis", method = "per_variable")

vimp_per_variable$final_dec_per_variable %>%
  select(-quantile_per_variable) %>%
  head()
````

As shown in the output above, when using per-variable p-values, ano variables are identified as informative after applying FWER or FDR correction. It is important to note that the `nsims` parameter in this example is set much lower than recommended in order to reduce vignette compilation time. For reliable results, `nsims` values should be increased.

## Output structure

So far, we have explored the `vimp_history` and `final_dec_pooled` (or `final_dec_per_variable`) elements in the output of the `vim_perm_sim_wrapper()` function. In addition to these, the output contains several other components. To demonstrate them, let’s revisit the output from the previous paragraph. As shown below, the `alpha` entry records the significance level $\alpha$ used in the final step of the procedure:

````{r alpha}
vimp_per_variable$alpha
````

The next element in the output of the `vim_perm_sim_wrapper()` function is `result_taken_from_previous_step`. If this entry is `TRUE`, it indicates that no variables survived the pre-selection process, so the reported results are taken from one of the pre-selection steps. If it is set to `FALSE` (as below), the results were obtained during the final step of the procedure.

````{r from_last_step}
vimp_per_variable$result_taken_from_previous_step
````

`time_elapsed` is a list containing the runtime of each step and the total time taken to execute the code, while `call` stores the call formula used to generate the output.

````{r time}
vimp_per_variable$time_elapsed
vimp_per_variable$call
````

The last entry in the output of the `vim_perm_sim_wrapper()` function is the `pre_selection` list, which contains two sublists: `step_1` and `step_2`. Both have the same structure. By default, each sublist includes:

- `vimp_history` - data frame storing VIMPs,
- `decision_per_variable` - data frame with p-values and decisions on whether a covariate is informative,
- `alpha` - the significance level used in the respective step.

The structure of the `pre_selection` list changes only if `save_vimp_history` is set to `last` or `none`. If one of these two options is chosen, `vimp_history` data frame will not be included for any pre-selection steps. The other two elements remain unchanged.

The code below demonstrates the described entries using `vimp_per_var_control` object created in the previous chunk of code.

````{r pre_selection}
# VIMP from 1st step
vimp_per_variable$pre_selection$step_1$vimp_history %>%
  select(1:5) %>%
  head()

# Which covariates were considered as informative in the 1st step?
vimp_per_variable$pre_selection$step_1$decision_per_variable %>%
  select(-quantile_per_variable) %>%
  head()

# The significance level used in the 1st step
vimp_per_variable$pre_selection$step_1$alpha

# Control parameters used in the 1st step
vimp_per_variable$pre_selection$step_1$control_parameters
````

## Plot your results

Let's use again the results obtained at the beginning of this tutorial, namely the following object:

````{r reminder,  eval = FALSE}
vimp_def <- vim_perm_sim_wrapper(nsims = c(20, 30, 50), entire_data = data_sub, outcome_var = "diagnosis")
````

Instead of just looking at the table that stores the decisions from the last step, we would like to have an appealing visual representation of our results. The `shadowVIMP` package provides an easy way to achieve this with the `plot_vimps()` function. To plot results based on pooled p-values, simply pass the output of the `vim_perm_sim_wrapper()` function as demonstrated below:

````{r plot_base, fig.width=13, fig.asp=0.8, out.width="115%"}
plot_vimps(wrapper_object = vimp_def)
````

The boxplots in the figure above display the VIMP measures for each covariate based on the `nsims` simulations from the final step of the procedure. The numbers on the left of the boxplots are unadjusted, FDR-adjusted and FWER-adjusted p-values respectively. To adjust the size of displayed p-values, increase the `text_size` parameter in the `plot_vimps()` function (default is 3).

To display a specific number of covariates, such as $10$, use the `filter_vars` parameter as shown below:

````{r filter_vars, fig.width=13, fig.asp=0.8, out.width="115%"}
plot_vimps(wrapper_object = vimp_def, filter_vars = 10, text_size = 4)
````

If you are working with a large dataset and many covariates survive to the last step of the procedure, it is recommended to set the `filter_vars` parameter to ensure the plot remains readable.

Here, we will again use the results based on per-variable p-values, keeping all other parameters at their default values:

````{r plot_per_var, eval=FALSE}
vimp_per_variable <- vim_perm_sim_wrapper(nsims = c(20, 30, 50), entire_data = data_sub, outcome_var = "diagnosis", method = "per_variable")
````

To use the `plot_vimps()` function for results based on per-variable p-values, the `pooled` parameter must be set to `FALSE`:

````{r plot_per_var2, fig.width=13, fig.asp=0.8, out.width="115%"}
plot_vimps(wrapper_object = vimp_per_variable, pooled = FALSE)
````

